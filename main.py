{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": None,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main.py\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from data import ModelNet40\n",
    "from model import PointNet, DGCNN\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from util import cal_loss, IOStream\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def _init_():\n",
    "    if not os.path.exists('checkpoints'):\n",
    "        os.makedirs('checkpoints')\n",
    "    if not os.path.exists('checkpoints/'+args.exp_name):\n",
    "        os.makedirs('checkpoints/'+args.exp_name)\n",
    "    if not os.path.exists('checkpoints/'+args.exp_name+'/'+'models'):\n",
    "        os.makedirs('checkpoints/'+args.exp_name+'/'+'models')\n",
    "    os.system('cp main.py checkpoints'+'/'+args.exp_name+'/'+'main.py.backup')\n",
    "    os.system('cp model.py checkpoints' + '/' + args.exp_name + '/' + 'model.py.backup')\n",
    "    os.system('cp util.py checkpoints' + '/' + args.exp_name + '/' + 'util.py.backup')\n",
    "    os.system('cp data.py checkpoints' + '/' + args.exp_name + '/' + 'data.py.backup')\n",
    "\n",
    "def train(args, io):\n",
    "    train_loader = DataLoader(ModelNet40(partition='train', num_points=args.num_points), num_workers=8,\n",
    "                              batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points), num_workers=8,\n",
    "                             batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "    #Try to load models\n",
    "    if args.model == 'pointnet':\n",
    "        model = PointNet(args).to(device)\n",
    "    elif args.model == 'dgcnn':\n",
    "        model = DGCNN(args).to(device)\n",
    "    else:\n",
    "        raise Exception(\"Not implemented\")\n",
    "    print(str(model))\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "    if args.use_sgd:\n",
    "        print(\"Use SGD\")\n",
    "        opt = optim.SGD(model.parameters(), lr=args.lr*100, momentum=args.momentum, weight_decay=1e-4)\n",
    "    else:\n",
    "        print(\"Use Adam\")\n",
    "        opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(opt, args.epochs, eta_min=args.lr)\n",
    "    \n",
    "    criterion = cal_loss\n",
    "\n",
    "    best_test_acc = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        ####################\n",
    "        # Train\n",
    "        ####################\n",
    "        train_loss = 0.0\n",
    "        count = 0.0\n",
    "        model.train()\n",
    "        train_pred = []\n",
    "        train_true = []\n",
    "        for data, label in train_loader:\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "            data = data.permute(0, 2, 1)\n",
    "            batch_size = data.size()[0]\n",
    "            opt.zero_grad()\n",
    "            logits = model(data)\n",
    "            loss = criterion(logits, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            count += batch_size\n",
    "            train_loss += loss.item() * batch_size\n",
    "            train_true.append(label.cpu().numpy())\n",
    "            train_pred.append(preds.detach().cpu().numpy())\n",
    "        train_true = np.concatenate(train_true)\n",
    "        train_pred = np.concatenate(train_pred)\n",
    "        outstr = 'Train %d, loss: %.6f, train acc: %.6f, train avg acc: %.6f' % (epoch,\n",
    "                                                                                 train_loss*1.0/count,\n",
    "                                                                                 metrics.accuracy_score(\n",
    "                                                                                     train_true, train_pred),\n",
    "                                                                                 metrics.balanced_accuracy_score(\n",
    "                                                                                     train_true, train_pred))\n",
    "        io.cprint(outstr)\n",
    "\n",
    "        ####################\n",
    "        # Test\n",
    "        ####################\n",
    "        test_loss = 0.0\n",
    "        count = 0.0\n",
    "        model.eval()\n",
    "        test_pred = []\n",
    "        test_true = []\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "            data = data.permute(0, 2, 1)\n",
    "            batch_size = data.size()[0]\n",
    "            logits = model(data)\n",
    "            loss = criterion(logits, label)\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            count += batch_size\n",
    "            test_loss += loss.item() * batch_size\n",
    "            test_true.append(label.cpu().numpy())\n",
    "            test_pred.append(preds.detach().cpu().numpy())\n",
    "        test_true = np.concatenate(test_true)\n",
    "        test_pred = np.concatenate(test_pred)\n",
    "        test_acc = metrics.accuracy_score(test_true, test_pred)\n",
    "        avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
    "        outstr = 'Test %d, loss: %.6f, test acc: %.6f, test avg acc: %.6f' % (epoch,\n",
    "                                                                              test_loss*1.0/count,\n",
    "                                                                              test_acc,\n",
    "                                                                              avg_per_class_acc)\n",
    "        io.cprint(outstr)\n",
    "        if test_acc >= best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            torch.save(model.state_dict(), 'checkpoints/%s/models/model.t7' % args.exp_name)\n",
    "\n",
    "\n",
    "def test(args, io):\n",
    "    test_loader = DataLoader(ModelNet40(partition='test', num_points=args.num_points),\n",
    "                             batch_size=args.test_batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "    #Try to load models\n",
    "    model = DGCNN(args).to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(args.model_path))\n",
    "    model = model.eval()\n",
    "    test_acc = 0.0\n",
    "    count = 0.0\n",
    "    test_true = []\n",
    "    test_pred = []\n",
    "    for data, label in test_loader:\n",
    "\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        data = data.permute(0, 2, 1)\n",
    "        batch_size = data.size()[0]\n",
    "        logits = model(data)\n",
    "        preds = logits.max(dim=1)[1]\n",
    "        test_true.append(label.cpu().numpy())\n",
    "        test_pred.append(preds.detach().cpu().numpy())\n",
    "    test_true = np.concatenate(test_true)\n",
    "    test_pred = np.concatenate(test_pred)\n",
    "    test_acc = metrics.accuracy_score(test_true, test_pred)\n",
    "    avg_per_class_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
    "    outstr = 'Test :: test acc: %.6f, test avg acc: %.6f'%(test_acc, avg_per_class_acc)\n",
    "    io.cprint(outstr)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='Point Cloud Recognition')\n",
    "    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',\n",
    "                        help='Name of the experiment')\n",
    "    parser.add_argument('--model', type=str, default='dgcnn', metavar='N',\n",
    "                        choices=['pointnet', 'dgcnn'],\n",
    "                        help='Model to use, [pointnet, dgcnn]')\n",
    "    parser.add_argument('--dataset', type=str, default='modelnet40', metavar='N',\n",
    "                        choices=['modelnet40'])\n",
    "    parser.add_argument('--batch_size', type=int, default=32, metavar='batch_size',\n",
    "                        help='Size of batch)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=16, metavar='batch_size',\n",
    "                        help='Size of batch)')\n",
    "    parser.add_argument('--epochs', type=int, default=250, metavar='N',\n",
    "                        help='number of episode to train ')\n",
    "    parser.add_argument('--use_sgd', type=bool, default=True,\n",
    "                        help='Use SGD')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.001, 0.1 if using sgd)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                        help='SGD momentum (default: 0.9)')\n",
    "    parser.add_argument('--no_cuda', type=bool, default=False,\n",
    "                        help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--eval', type=bool,  default=False,\n",
    "                        help='evaluate the model')\n",
    "    parser.add_argument('--num_points', type=int, default=1024,\n",
    "                        help='num of points to use')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                        help='dropout rate')\n",
    "    parser.add_argument('--emb_dims', type=int, default=1024, metavar='N',\n",
    "                        help='Dimension of embeddings')\n",
    "    parser.add_argument('--k', type=int, default=20, metavar='N',\n",
    "                        help='Num of nearest neighbors to use')\n",
    "    parser.add_argument('--model_path', type=str, default='', metavar='N',\n",
    "                        help='Pretrained model path')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    _init_()\n",
    "\n",
    "    io = IOStream('checkpoints/' + args.exp_name + '/run.log')\n",
    "    io.cprint(str(args))\n",
    "\n",
    "    args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        io.cprint(\n",
    "            'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    else:\n",
    "        io.cprint('Using CPU')\n",
    "\n",
    "    if not args.eval:\n",
    "        train(args, io)\n",
    "    else:\n",
    "        test(args, io)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
